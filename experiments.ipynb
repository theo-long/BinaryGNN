{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2107430",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8b4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import larq as lq\n",
    "\n",
    "from utils import prepare_dataset, generate_data_loaders\n",
    "from models import generate_quantized_gcn, generate_standard_gcn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c620696",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5231a464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n",
      "Dataset:  cora\n",
      "Size of train set: 140\n",
      "Size of val set: 500\n",
      "Size of test set: 1000\n",
      "Num classes: 7\n",
      "Num features: 1433\n",
      "Pre-processing node features\n",
      "Dataset:  pubmed\n",
      "Size of train set: 60\n",
      "Size of val set: 500\n",
      "Size of test set: 1000\n",
      "Num classes: 3\n",
      "Num features: 500\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cora_dataset = prepare_dataset(\"Cora\")\n",
    "pubmed_dataset = prepare_dataset(\"PubMed\")\n",
    "\n",
    "cora_tr, cora_va, cora_te = generate_data_loaders(cora_dataset)\n",
    "pubmed_tr, pubmed_va, pubmed_te = generate_data_loaders(cora_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d691e50",
   "metadata": {},
   "source": [
    "# Experiment 1: GCN baseline (no quantization)\n",
    "\n",
    "Following the architecture and hyperparameters settings of Kipf & Welling (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d522c01",
   "metadata": {},
   "source": [
    "## Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c106ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"graph_conv_1\" (type GraphConv).\n\nin user code:\n\n    File \"/Users/tlong/Documents/code/BinaryGNN/models.py\", line 17, in call  *\n        return tf.sparse.sparse_dense_matmul(self.a, inputs)\n\n    TypeError: Input must be a SparseTensor.\n\n\nCall arguments received by layer \"graph_conv_1\" (type GraphConv):\n  • inputs=tf.Tensor(shape=(None, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_shapes \u001b[38;5;241m=\u001b[39m (cora_dataset\u001b[38;5;241m.\u001b[39mgraphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], cora_dataset\u001b[38;5;241m.\u001b[39mgraphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_standard_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcora_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/BinaryGNN/models.py:125\u001b[0m, in \u001b[0;36mgenerate_standard_gcn\u001b[0;34m(channels, input_shapes, output_features, dropout_rate, layers, activation, use_batch_norm, batch_norm_momentum, batch_norm_epsilon, batch_norm_center, batch_norm_scale, single_batch_norm, **layer_kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m x_intermediate \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(rate\u001b[39m=\u001b[39mdropout_rate)(x_intermediate)\n\u001b[1;32m    122\u001b[0m x_intermediate \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39mchannels, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlayer_kwargs)(\n\u001b[1;32m    123\u001b[0m     x_intermediate\n\u001b[1;32m    124\u001b[0m )\n\u001b[0;32m--> 125\u001b[0m x_intermediate \u001b[39m=\u001b[39m GraphConv(adj_matrix)(x_intermediate)\n\u001b[1;32m    126\u001b[0m x_intermediate \u001b[39m=\u001b[39m activation()(x_intermediate)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m use_batch_norm \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m single_batch_norm):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/envs/bi-gcn/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/rn/jqrwv4s94353h34h4r7t__sm0000gn/T/__autograph_generated_filestteo5rl.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39msparse_dense_matmul, (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39ma, ag__\u001b[39m.\u001b[39mld(inputs)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"graph_conv_1\" (type GraphConv).\n\nin user code:\n\n    File \"/Users/tlong/Documents/code/BinaryGNN/models.py\", line 17, in call  *\n        return tf.sparse.sparse_dense_matmul(self.a, inputs)\n\n    TypeError: Input must be a SparseTensor.\n\n\nCall arguments received by layer \"graph_conv_1\" (type GraphConv):\n  • inputs=tf.Tensor(shape=(None, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "input_shapes = (cora_dataset.graphs[0].x.shape[1], cora_dataset.graphs[0].a.shape[1])\n",
    "model = generate_standard_gcn(channels=64, input_shapes=input_shapes, output_features=cora_dataset.n_labels, dropout_rate=0.5, layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aada8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec31f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cora_dataset.graphs[0].a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7171b",
   "metadata": {},
   "source": [
    "## PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = generate_standard_gcn(channels=64, input_shapes=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b8172",
   "metadata": {},
   "source": [
    "# Experiment 2: Quantized GCN Baseline (Same as paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebaebd",
   "metadata": {},
   "source": [
    "# Experiment 3: Dropout - reducing the dropout rate, removing dropout, and putting dropout before vs. after the binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be612ac",
   "metadata": {},
   "source": [
    "# Experiment 4: Allow batchnorm to be trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504573a",
   "metadata": {},
   "source": [
    "# Experiment 5: Batchnorm before every layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd19a2",
   "metadata": {},
   "source": [
    "# Experiment 6: Effect of l2 regularization, using binary regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43354b61",
   "metadata": {},
   "source": [
    "# Experiment 7: Hyperparameter tuning (allow the quantizers to change as part of this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6edeb",
   "metadata": {},
   "source": [
    "# Experiment 8: Increase number or width of layers (compare to standard GCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d76c5",
   "metadata": {},
   "source": [
    "# Experiment 9: Use Bop Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf72f68",
   "metadata": {},
   "source": [
    "# Experiment 10: Use two-part learning, start with full precision, then do second phase of binarized learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2ea99",
   "metadata": {},
   "source": [
    "# Experiment 11: Ternary version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('bi-gcn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7fc9faa0f7e76d92249c48b1d81efa906519acbef42a6025d885e5ccde9a50e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
